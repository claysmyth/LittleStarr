{
    "sourceFile": "data_processing/data_transforms.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1681939678725,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1681939678725,
            "name": "Commit-0",
            "content": "import dask.dataframe as dd\nimport polars as pl\nfrom multipledispatch import dispatch\n\n\n@dispatch(dd.core.DataFrame, list)\ndef get_sleep_stage_dict(df, cols):\n    \"\"\"\n    returns dictionary with key-value pair as sleep stage (int) : n x size(cols) dataframe corresponding to that sleep stage\n    :param df: Either a pandas, Dask, or polars dataframe\n    :param cols: columns to keep in sleep_stage_dict\n    :return: dict of each sleep stage paired with raw data corresponding to that stage\n    \"\"\"\n    sleep_stages = df['SleepStage'].unique().compute().values\n    df_gb = df.groupby('SleepStage')\n    sleep_stage_data_dict = {stage: df_gb[cols].get_group(stage) for stage in sleep_stages}\n    return sleep_stage_data_dict\n\n\n@dispatch(pl.internals.dataframe.frame.DataFrame, list)\ndef get_sleep_stage_dict(df, cols):\n    \"\"\"\n    returns dictionary with key-value pair as sleep stage (int) : n x size(cols) dataframe corresponding to that sleep stage\n    :param df: Either a pandas, Dask, or polars dataframe\n    :param cols: columns to keep in sleep_stage_dict\n    :return: dict of each sleep stage paired with raw data corresponding to that stage\n    \"\"\"\n    sleep_stages = df.select('SleepStage').unique().to_numpy().squeeze()\n    sleep_stage_data_dict = {stage: df.select(pl.col(cols)).filter(pl.col('SleepStage') == stage) for stage in sleep_stages}\n    return sleep_stage_data_dict\n\n\ndef chunk_df_by_timesegment(df, interval='1s', period='2s', sample_rate=500, align_with_PB_outputs=False, td_columns=['TD_BG', 'TD_key2', 'TD_key3']):\n    \"\"\"\n    Chunk a dataframe  based on a time interval and period.\n    The period is the length of the time segment, the interval is the time between the start of each time segment.\n    \n    Parameters:\n    df (DataFrame): The dataframe to be chunked\n    interval (str): The time interval between the start of each time segment. Default is '1s'\n    period (str): The length of each time segment. Default is '2s'\n    align_with_PB_outputs (bool): If True, the time segments will be aligned with the Power Band outputs. Default is False.\n    \"\"\"\n    td_cols = [col for col in df.columns if col in td_columns]\n    # TODO: Remove hardcoding of 'SleepStage', should refer to it as a variable\n    if align_with_PB_outputs:\n        df_pb_count = df.join(\n            df.filter(pl.col('Power_Band8').is_not_null()).select(\n                'DerivedTime').with_row_count(),\n            on='DerivedTime', how='left').with_columns(pl.col('row_nr').fill_null(strategy='backward')).rename({'row_nr': 'PB_count'})\n\n        df_pb_count = df_pb_count.with_columns([\n            pl.when( (pl.col('PB_count') % 2) == 0).then(pl.lit(None)).otherwise(pl.col('PB_count')).fill_null(strategy='backward').alias('PB_count_odd'),\n            pl.when( (pl.col('PB_count') % 2) == 1).then(pl.lit(None)).otherwise(pl.col('PB_count')).fill_null(strategy='backward').alias('PB_count_even')\n        ])\n\n        df_pb_count = df_pb_count.groupby(['SleepStage', 'PB_count_even']).agg(\n            [\n                pl.col('DerivedTime'),\n                pl.col('^Power_Band.*$').drop_nulls().first(),\n                pl.col('^TD_.*$'),\n                pl.col(td_cols[0]).count().alias('TD_count')\n            ]).rename({'PB_count_even': 'PB_ind'}).vstack(\n                df_pb_count.groupby(['SleepStage', 'PB_count_odd']).agg(\n                    [\n                        pl.col('DerivedTime'),\n                        pl.col('^Power_Band.*$').drop_nulls().first(),\n                        pl.col('^TD_.*$'),\n                pl.col(td_cols[0]).count().alias('TD_count')\n                    ]).rename({'PB_count_odd': 'PB_ind'})\n        ).select(pl.all().shrink_dtype()).rechunk()\n\n        df_chunked = df_pb_count\n    else:\n        df_grouped = df.sort('localTime').groupby_dynamic('localTime', every=interval, period=period, by=['SessionIdentity', 'SleepStage']).agg([\n            pl.col('DerivedTime'),\n            pl.col('^Power_Band.*$').drop_nulls().first(),\n            pl.col('^TD_.*$'),\n                pl.col(td_cols[0]).count().alias('TD_count')]).select(pl.all().shrink_dtype())\n\n        df_grouped = df_grouped.with_columns(\n                    pl.col(td_cols[0]).arr.eval(pl.element().is_null().any()).alias('TD_null')\n                ).filter((pl.col('TD_count') == int(period[0]) * sample_rate ) &\n                        (pl.col('TD_null').arr.contains(False))\n                        )\n        df_chunked = df_grouped\n    return df_chunked"
        }
    ]
}